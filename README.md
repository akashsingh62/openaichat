# ğŸ¤– Local AI Chat App using Ollama + Streamlit

A sleek, privacy-first conversational chat app powered by **Ollama's LLaMA3** model and built with **Streamlit**. Ask questions and get responses â€” all running locally with **no API keys, no cloud dependencies**.

---

## ğŸ“¸ Demo

![Chat App Screenshot](chatbot screen shot .png)

---

## âœ¨ Features

âœ… Fully local â€” no internet, no cloud model  
âœ… Powered by LLaMA3 via [Ollama](https://ollama.com)  
âœ… Responsive UI using Streamlit  
âœ… Chat history display  
âœ… Modern dark theme  

---

## ğŸš€ How It Works

- User enters a query in the text box.
- The prompt is passed to `Ollama` via `ChatOllama`.
- The response is returned and rendered in the chat window.
- All chats are stored in `st.session_state` for history.

---

## ğŸ› ï¸ Installation & Setup

### 1. Clone this repository

```bash
git clone https://github.com/your-username/ollama-streamlit-chat.git
cd ollama-streamlit-chat
